# -*- coding: utf-8 -*-
"""Digits Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mHbyA8MnSCUDFXYyiwRoXHvo4n-A7ucN
"""

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import ImageGrid
import keras
import tensorflow
import os
from sklearn import metrics
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import validation_curve
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
import seaborn as sns
from sklearn.model_selection import train_test_split
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from keras import callbacks
from keras.callbacks import EarlyStopping, ModelCheckpoint 
from keras.datasets import mnist 
import warnings
warnings.filterwarnings("ignore")

(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train.shape, y_train.shape, X_test.shape, y_test.shape #(1,2,3)=(1,6)

plt.imshow(X_train [0] , cmap= 'binary')

n_rows = 5
n_cols = 10
plt.figure(figsize=(15, 6))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(X_train[index],cmap="binary")
        #plt.axis('off')
        plt.title(y_train[index], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()

X_train = X_train.astype (np.float32)/255 
X_test = X_test.astype(np. float32)/255

"""#**SVM**"""

nsamples, nx, ny = X_train.shape
d2_train_dataset = X_train.reshape((nsamples,nx*ny))

nsampless, nnx, nny = X_test.shape
d1_train_dataset = X_test.reshape((nsampless,nnx*nny))

model_linear = SVC(kernel='linear')
model_linear.fit(d2_train_dataset, y_train)

y_pred = model_linear.predict(d1_train_dataset)

svm_pred=metrics.accuracy_score(y_true=y_test, y_pred=y_pred)
SVM_acc=round(svm_pred*100,2)
print("SVM Accuracy:",SVM_acc)

"""# **KNN**"""

import operator 
from operator import itemgetter

def euc_dist(x1, x2):
    return np.sqrt(np.sum((x1-x2)**2))

class KNN:
    def __init__(self, K):
        self.K = K

class KNN:
    def __init__(self, K):
        self.K = K
    def fit(self, x_train, y_train):
        self.X_train = x_train
        self.Y_train = y_train

class KNN:
    def predict(self, X_test):
        predictions = [] 
        for i in range(len(X_test)):
            dist = np.array([euc_dist(X_test[i], x_t) for x_t in  self.X_train])
            dist_sorted = dist.argsort()[:self.K]
            neigh_count = {}
            for idx in dist_sorted:
                if self.Y_train[idx] in neigh_count:
                    neigh_count[self.Y_train[idx]] += 1
                else:
                    neigh_count[self.Y_train[idx]] = 1
            sorted_neigh_count = sorted(neigh_count.items(),    
            key=operator.itemgetter(1), reverse=True)
            predictions.append(sorted_neigh_count[0][0]) 
        return predictions

from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier

kVals = np.arange(3,20,2)
accuracies = []
for k in kVals:
  model = KNeighborsClassifier(k)
  model.fit(d2_train_dataset, y_train)
  predk = model.predict(d1_train_dataset)
  acc = accuracy_score(y_test, predk)
  accuracies.append(acc)
  print("K = "+str(k)+"; Accuracy: "+str(acc))

max_accuracy = max(accuracies)
KNN_acc=round(max_accuracy*100,2)
print("KNN Accuracy:",KNN_acc)

"""#**CNN**"""

X_train = np.expand_dims (X_train, -1)
X_test = np.expand_dims (X_test, -1)

y_train = keras.utils.np_utils.to_categorical(y_train)
y_test = keras.utils.np_utils.to_categorical(y_test)
y_train

X_train.shape, y_train.shape, X_test.shape, y_test.shape

model = Sequential()
model.add(Conv2D(32, (3,3), input_shape = (28, 28, 1), activation='relu') )
model.add(MaxPool2D((2, 2)))

model.add(Conv2D(64, (3,3), activation='relu')) 
model.add(MaxPool2D((2, 2)))

model.add(Flatten())
model.add(Dropout(0.25))
model.add(Dense(10, activation="softmax"))

model.summary()

model.compile(optimizer= 'adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])

es = EarlyStopping (monitor='val_accuracy', mode="max", patience= 5, verbose= 1,restore_best_weights=True)
his = model.fit(X_train, y_train, epochs= 50, validation_split= 0.2,callbacks=[es] )

model_name = 'digits_reco.model'
model.save(model_name, save_format='model')
model_save_name = 'bestmodels.model'
mc=ModelCheckpoint(F"/content/drive/My Drive/{model_save_name}", monitor='val_acc', verbose=1, save_weights_only=False, save_best_only=False, mode='max')
cb=[es,mc]
cb

model_S = keras.models.load_model("/content/digits_reco.model")

score = model_S.evaluate (X_test, y_test)
CNN=score[1]*100
CNN_acc=round(CNN,2)
print("CNN model accuracy is",CNN_acc)

Class = ['SVM','KNN','CNN']
values=[SVM_acc,KNN_acc,CNN_acc] 
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.bar(Class, values, color=("Blue","Red","Black"))
plt.ylim(90, 100)
plt.xlabel("Classifications")
plt.ylabel("Accuracy")
plt.title(" ")
plt.show()

fig = plt.figure()
plt.subplot(2,1,1)
plt.plot(his.history['accuracy'])
plt.plot(his.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')

plt.subplot(2,1,2)
plt.plot(his.history['loss'])
plt.plot(his.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.tight_layout()